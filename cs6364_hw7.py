# -*- coding: utf-8 -*-
"""CS6364_HW7.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1u9JnIiIJclMQJA7KTIGvj8d7Wn0FCh3Z
"""

# torch
import torch
import torch.nn    as nn
import torch.optim as optim
import torch.nn.functional as F
from torch.autograd import Variable

# torch utils
import torchvision
import torchvision.transforms as transforms

# additional libraries
import math
import numpy             as np
import pandas as pd
import matplotlib.pyplot as plt
from typing import List, Text
# %matplotlib inline

from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, classification_report, accuracy_score
import cv2
from google.colab.patches import cv2_imshow

# version check
# print(torch.__version__)

"""# QUESTION 1"""

def show_grayscale_image(tensor):
    tensor = (tensor - tensor.min()).div(tensor.max() - tensor.min())
    tensor = torch.squeeze(tensor)
    img = np.uint8(tensor.mul(255).numpy()) 
    cv2_imshow(img)

def forward(tensor, weights, text):
    print(text)
    afterconv = nn.functional.conv2d(tensor,weights)
    show_grayscale_image(afterconv)
    afterrelu = nn.functional.relu_(afterconv)
    show_grayscale_image(afterrelu)
    aftermaxpool = nn.functional.max_pool2d(input=afterrelu,kernel_size=2)
    show_grayscale_image(aftermaxpool)

weights = torch.Tensor([[[[1.0, 0.0, -1.0],
                          [2.0, 0.0, -2.0],
                          [1.0, 0.0, -1.0]]]])
data = torch.from_numpy(cv2.cvtColor(cv2.imread('Q1.jpg'), cv2.COLOR_BGR2GRAY)).float().unsqueeze(0).unsqueeze(0)
forward(data, weights,"Vertical Edge (Convolution, Relu, MaxPool)")
print()
forward(data, weights.permute(0,1,3,2),"Horizontal Edge (Convolution, Relu, MaxPool)")

"""# QUESTION 2"""

!pip install python-mnist
from mnist import MNIST

mndata = MNIST('data')
train_images, train_labels = mndata.load_training()
# or
test_images, test_labels = mndata.load_testing()

# data
DATA_NUM_TRAIN         = 60000
DATA_NUM_TEST          = 10000
DATA_CHANNELS          = 1
DATA_ROWS              = 28
DATA_COLS              = 28
DATA_CLASSES           = 10

# display
DISPLAY_ROWS   = 8
DISPLAY_COLS   = 4
DISPLAY_COL_IN = 10
DISPLAY_ROW_IN = 25
DISPLAY_NUM    = DISPLAY_ROWS*DISPLAY_COLS

train_data = np.asarray(train_images).astype(np.float32)
train_data = train_data.reshape(DATA_NUM_TRAIN, 1, DATA_ROWS, DATA_COLS)

train_labels = np.asarray(train_labels).astype(np.int32)

test_data = np.asarray(test_images).astype(np.float32)
test_data = test_data.reshape(DATA_NUM_TEST, 1, DATA_ROWS, DATA_COLS)

test_labels = np.asarray(test_labels).astype(np.int32)

# debug
print(train_data.shape)   # (60000, 1, 28, 28)
print(train_labels.shape) # (60000,)
print(test_data.shape)    # (10000, 1, 28, 28)
print(test_labels.shape)  # (10000,)

cv2_imshow(train_data[0][0])
cv2_imshow(test_data[0][0])
cv2_imshow(train_data[1][0])
cv2_imshow(test_data[1][0])
cv2_imshow(train_data[2][0])
cv2_imshow(test_data[2][0])

X_train, X_test, y_train, y_test = train_test_split(train_data, train_labels, test_size = 0.1)
print(X_train.shape)
print(X_test.shape)
print(y_train.shape)
print(y_test.shape)

X_train = torch.from_numpy(X_train).float()
X_test = torch.from_numpy(X_test).float()
y_train = torch.from_numpy(y_train).long()
y_test = torch.from_numpy(y_test).long()

training_set = torch.utils.data.TensorDataset(X_train,y_train)
validation_set = torch.utils.data.TensorDataset(X_test,y_test)

dataloader_train = torch.utils.data.DataLoader(training_set, batch_size=32, shuffle=True,  num_workers=4, drop_last=True)
dataloader_test  = torch.utils.data.DataLoader(validation_set, batch_size=32, shuffle=False, num_workers=4, drop_last=True)

class Model(nn.Module):

    # initialization
    def __init__(self):
        super(Model, self).__init__()
        self.layer1 = nn.ModuleList()
        self.layer1.append(nn.Conv2d(1,4,kernel_size=(3,3),padding=(1, 1)))
        self.layer1.append(nn.BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True))
        self.layer1.append(nn.ReLU(inplace=True))
        self.layer1.append(nn.MaxPool2d(kernel_size=2))

        self.layer2 = nn.ModuleList()
        self.layer2.append(nn.Conv2d(4,4,kernel_size=(3,3),padding=(1, 1)))
        self.layer2.append(nn.BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True))
        self.layer2.append(nn.ReLU(inplace=True))
        self.layer2.append(nn.MaxPool2d(kernel_size=2))

        self.layer3 = nn.ModuleList()
        self.layer3.append(nn.Flatten())
        self.layer3.append(nn.Linear(196,10))
        self.layer3.append(nn.Softmax(1))

    def forward(self, x):
        for layer in self.layer1:
            x = layer(x)
    
        for layer in self.layer2:
            x = layer(x)
  
        for layer in self.layer3:
            x = layer(x)

        return x

model = Model()

# visualization
print(model)

# training (linear warm up with cosine decay learning rate)
TRAINING_LR_MAX          = 0.001
TRAINING_LR_INIT_SCALE   = 0.01
TRAINING_LR_INIT_EPOCHS  = 5
TRAINING_LR_FINAL_SCALE  = 0.01
TRAINING_LR_FINAL_EPOCHS = 20
# TRAINING_LR_FINAL_EPOCHS = 2 # uncomment for a quick test
TRAINING_NUM_EPOCHS      = TRAINING_LR_INIT_EPOCHS + TRAINING_LR_FINAL_EPOCHS
TRAINING_LR_INIT         = TRAINING_LR_MAX*TRAINING_LR_INIT_SCALE
TRAINING_LR_FINAL        = TRAINING_LR_MAX*TRAINING_LR_FINAL_SCALE

# for data in dataloader_train:
#    inputs, labels = data
#    outputs = model(inputs)
#    loss    = criterion(outputs, labels)
#    loss.backward()
#    optimizer.step()

# start epoch
start_epoch = 0

# learning rate schedule
def lr_schedule(epoch):

    # linear warmup followed by cosine decay
    if epoch < TRAINING_LR_INIT_EPOCHS:
        lr = (TRAINING_LR_MAX - TRAINING_LR_INIT)*(float(epoch)/TRAINING_LR_INIT_EPOCHS) + TRAINING_LR_INIT
    else:
        lr = (TRAINING_LR_MAX - TRAINING_LR_FINAL)*max(0.0, math.cos(((float(epoch) - TRAINING_LR_INIT_EPOCHS)/(TRAINING_LR_FINAL_EPOCHS - 1.0))*(math.pi/2.0))) + TRAINING_LR_FINAL

    return lr

# error (softmax cross entropy)
criterion = nn.CrossEntropyLoss()

# optimizer
optimizer = optim.Adam(model.parameters(), lr=0.001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0, amsgrad=False)

# specify the device as the GPU if present with fallback to the CPU
device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
# print(device)

# transfer the network to the device
model.to(device)

training_accuracy = []
validation_loss = []
# cycle through the epochs
for epoch in range(start_epoch, TRAINING_NUM_EPOCHS):

    # initialize train set statistics
    model.train()
    training_loss = 0.0
    num_batches   = 0

    # set the learning rate for the epoch
    for g in optimizer.param_groups:
        g['lr'] = lr_schedule(epoch)

    # cycle through the train set
    for data in dataloader_train:

        # extract a batch of data and move it to the appropriate device
        inputs, labels = data
        inputs, labels = inputs.to(device), labels.to(device)

        # zero the parameter gradients
        optimizer.zero_grad()

        # forward pass, loss, backward pass and weight update
        outputs = model(inputs)
        loss    = criterion(outputs, labels)
        loss.backward()
        optimizer.step()

        # update statistics
        training_loss = training_loss + loss.item()
        num_batches   = num_batches + 1

    # initialize test set statistics
    model.eval()
    test_correct = 0
    test_total   = 0

    # no weight update / no gradient needed
    with torch.no_grad():

        # cycle through the test set
        for data in dataloader_test:

            # extract a batch of data and move it to the appropriate device
            inputs, labels = data
            inputs, labels = inputs.to(device), labels.to(device)

            # forward pass and prediction
            outputs      = model(inputs)
            _, predicted = torch.max(outputs.data, 1)

            # update test set statistics
            test_total   = test_total + labels.size(0)
            test_correct = test_correct + (predicted == labels).sum().item()

    # epoch statistics
    print('Epoch {0:2d} lr = {1:8.6f} avg loss = {2:8.6f} accuracy = {3:5.2f}'.format(epoch, lr_schedule(epoch), (training_loss/num_batches)/32, (100.0*test_correct/test_total)))
    training_accuracy.append((training_loss/num_batches)/32)
    validation_loss.append((100.0*test_correct/test_total))

DATA_CLASS_NAMES = ('T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot')

# initialize test set statistics
model.eval()
test_correct = 0
test_total   = 0

# initialize class statistics
class_correct = list(0. for i in range(10))
class_total   = list(0. for i in range(10))

# no weight update / no gradient needed
with torch.no_grad():

    # cycle through the test set
    for data in dataloader_test:

        # extract a batch of data and move it to the appropriate device
        inputs, labels = data
        inputs, labels = inputs.to(device), labels.to(device)

        # forward pass and prediction
        outputs      = model(inputs)
        _, predicted = torch.max(outputs.data, 1)

        # update test set statistics
        test_total   = test_total + labels.size(0)
        test_correct = test_correct + (predicted == labels).sum().item()

        # update class statistics
        c = (predicted == labels).squeeze()
        for i in range(labels.size(0)):
            label                 = labels[i]
            class_correct[label] += c[i].item()
            class_total[label]   += 1

# test set statistics
print('Accuracy of test set = {0:5.2f}'.format((100.0*test_correct/test_total)))
print('')

# class statistics
for i in range(10):
    print('Accuracy of {0:5s}    = {1:5.2f}'.format(DATA_CLASS_NAMES[i], (100.0*class_correct[i]/class_total[i])))

plt.title('accuracy & values vs epoch (10000 train)')
plt.plot(range(len(training_accuracy)),training_accuracy, label= "Accuracy")
plt.plot(range(len(validation_loss)),validation_loss, label= "AvgLoss")
plt.xlabel('Epoch')
plt.ylabel('values')
plt.show()

# print(test_data.shape)    # (10000, 1, 28, 28)
# print(test_labels.shape)  # (10000,)
test_data = torch.from_numpy(test_data).float()
test_labels = torch.from_numpy(test_labels).long()
test_set = torch.utils.data.TensorDataset(test_data,test_labels)
test_dataloader = torch.utils.data.DataLoader(training_set, batch_size=32, shuffle=True,  num_workers=4, drop_last=True)

# initialize test set statistics
model.eval()
test_correct = 0
test_total   = 0

# initialize class statistics
class_correct = list(0. for i in range(10))
class_total   = list(0. for i in range(10))

# no weight update / no gradient needed
with torch.no_grad():

    # cycle through the test set
    for data in test_dataloader:

        # extract a batch of data and move it to the appropriate device
        inputs, labels = data
        inputs, labels = inputs.to(device), labels.to(device)

        # forward pass and prediction
        outputs      = model(inputs)
        _, predicted = torch.max(outputs.data, 1)

        # update test set statistics
        test_total   = test_total + labels.size(0)
        test_correct = test_correct + (predicted == labels).sum().item()

        # update class statistics
        c = (predicted == labels).squeeze()
        for i in range(labels.size(0)):
            label                 = labels[i]
            class_correct[label] += c[i].item()
            class_total[label]   += 1

# test set statistics
print('Accuracy of test set = {0:5.2f}'.format((100.0*test_correct/test_total)))
print('')

# class statistics
for i in range(10):
    print('Accuracy of {0:5s}    = {1:5.2f}'.format(DATA_CLASS_NAMES[i], (100.0*class_correct[i]/class_total[i])))

"""# QUESTION 3"""

class LeNet5(nn.Module):

    # initialization
    def __init__(self):
        super(LeNet5, self).__init__()
        self.layer1 = nn.ModuleList()
        self.layer1.append(nn.Conv2d(1,6,kernel_size=(5,5),padding=(2, 2)))
        self.layer1.append(nn.Tanh())
        self.layer1.append(nn.AvgPool2d(kernel_size=(2,2),stride=(2,2)))
        self.layer1.append(nn.Tanh())

        self.layer2 = nn.ModuleList()
        self.layer2.append(nn.Conv2d(6,16,kernel_size=(5,5)))
        self.layer2.append(nn.Tanh())
        self.layer2.append(nn.AvgPool2d(kernel_size=(2,2),stride=(2,2)))
        self.layer2.append(nn.Tanh())
        self.layer2.append(nn.Conv2d(16,120,kernel_size=(5,5)))
        self.layer2.append(nn.Tanh())

        self.layer3 = nn.ModuleList()
        self.layer3.append(nn.Flatten())
        self.layer3.append(nn.Linear(120,84))
        self.layer3.append(nn.Tanh())
        self.layer3.append(nn.Linear(84,10))
        self.layer3.append(nn.Softmax(1))

    def forward(self, x):
        for layer in self.layer1:
            x = layer(x)

        for layer in self.layer2:
            x = layer(x)

        for layer in self.layer3:
            x = layer(x)

        return x

model = LeNet5()

# visualization
print(model)

# start epoch
start_epoch = 0

# error (softmax cross entropy)
criterion = nn.CrossEntropyLoss()

# optimizer
optimizer = optim.Adam(model.parameters(), lr=0.001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0, amsgrad=False)

# specify the device as the GPU if present with fallback to the CPU
device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
# print(device)

# transfer the network to the device
model.to(device)

training_accuracy = []
validation_loss = []
# cycle through the epochs
for epoch in range(start_epoch, TRAINING_NUM_EPOCHS):

    # initialize train set statistics
    model.train()
    training_loss = 0.0
    num_batches   = 0

    # set the learning rate for the epoch
    for g in optimizer.param_groups:
        g['lr'] = lr_schedule(epoch)

    # cycle through the train set
    for data in dataloader_train:

        # extract a batch of data and move it to the appropriate device
        inputs, labels = data
        inputs, labels = inputs.to(device), labels.to(device)

        # zero the parameter gradients
        optimizer.zero_grad()

        # forward pass, loss, backward pass and weight update
        outputs = model(inputs)
        loss    = criterion(outputs, labels)
        loss.backward()
        optimizer.step()

        # update statistics
        training_loss = training_loss + loss.item()
        num_batches   = num_batches + 1

    # initialize test set statistics
    model.eval()
    test_correct = 0
    test_total   = 0

    # no weight update / no gradient needed
    with torch.no_grad():

        # cycle through the test set
        for data in dataloader_test:

            # extract a batch of data and move it to the appropriate device
            inputs, labels = data
            inputs, labels = inputs.to(device), labels.to(device)

            # forward pass and prediction
            outputs      = model(inputs)
            _, predicted = torch.max(outputs.data, 1)

            # update test set statistics
            test_total   = test_total + labels.size(0)
            test_correct = test_correct + (predicted == labels).sum().item()

    # epoch statistics
    print('Epoch {0:2d} lr = {1:8.6f} avg loss = {2:8.6f} accuracy = {3:5.2f}'.format(epoch, lr_schedule(epoch), (training_loss/num_batches)/32, (100.0*test_correct/test_total)))
    training_accuracy.append((training_loss/num_batches)/32)
    validation_loss.append((100.0*test_correct/test_total))

# initialize test set statistics
model.eval()
test_correct = 0
test_total   = 0

# initialize class statistics
class_correct = list(0. for i in range(10))
class_total   = list(0. for i in range(10))

# no weight update / no gradient needed
with torch.no_grad():

    # cycle through the test set
    for data in dataloader_test:

        # extract a batch of data and move it to the appropriate device
        inputs, labels = data
        inputs, labels = inputs.to(device), labels.to(device)

        # forward pass and prediction
        outputs      = model(inputs)
        _, predicted = torch.max(outputs.data, 1)

        # update test set statistics
        test_total   = test_total + labels.size(0)
        test_correct = test_correct + (predicted == labels).sum().item()

        # update class statistics
        c = (predicted == labels).squeeze()
        for i in range(labels.size(0)):
            label                 = labels[i]
            class_correct[label] += c[i].item()
            class_total[label]   += 1

# test set statistics
print('Accuracy of test set = {0:5.2f}'.format((100.0*test_correct/test_total)))
print('')

# class statistics
for i in range(10):
    print('Accuracy of {0:5s}    = {1:5.2f}'.format(DATA_CLASS_NAMES[i], (100.0*class_correct[i]/class_total[i])))

plt.title('accuracy & values vs epoch (10000 train)')
plt.plot(range(len(training_accuracy)),training_accuracy, label= "Accuracy")
plt.plot(range(len(validation_loss)),validation_loss, label= "AvgLoss")
plt.xlabel('Epoch')
plt.ylabel('values')
plt.show()

# initialize test set statistics
model.eval()
test_correct = 0
test_total   = 0

# initialize class statistics
class_correct = list(0. for i in range(10))
class_total   = list(0. for i in range(10))

# no weight update / no gradient needed
with torch.no_grad():

    # cycle through the test set
    for data in test_dataloader:

        # extract a batch of data and move it to the appropriate device
        inputs, labels = data
        inputs, labels = inputs.to(device), labels.to(device)

        # forward pass and prediction
        outputs      = model(inputs)
        _, predicted = torch.max(outputs.data, 1)

        # update test set statistics
        test_total   = test_total + labels.size(0)
        test_correct = test_correct + (predicted == labels).sum().item()

        # update class statistics
        c = (predicted == labels).squeeze()
        for i in range(labels.size(0)):
            label                 = labels[i]
            class_correct[label] += c[i].item()
            class_total[label]   += 1

# test set statistics
print('Accuracy of test set = {0:5.2f}'.format((100.0*test_correct/test_total)))
print('')

# class statistics
for i in range(10):
    print('Accuracy of {0:5s}    = {1:5.2f}'.format(DATA_CLASS_NAMES[i], (100.0*class_correct[i]/class_total[i])))